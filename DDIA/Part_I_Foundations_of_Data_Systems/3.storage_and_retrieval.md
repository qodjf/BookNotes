# 存储和检索
从最基本的层面看，数据库只需要做两件事：把数据存进去，把数据找出来。存储和检索是息息相关的。本章所关注的正是这两个问题。

作为应用开发者，为什么要关注数据库内部的存储和检索呢？因为为了针对你的工作负载对数据库进行调优时，最好对存储引擎的底层机制有一个大概的了解。

特别地是，针对事务型工作负载和针对分析型工作负载的存储引擎优化存在很大的差异。

我们首先讨论存储引擎，即日志结构的存储引擎 (LSM-Tree) 和面向页的存储引擎 (B-Tree)。
## 核心数据结构
先看一个世界上最简单的数据库，由两个 Bash 函数实现：
```bash
db_set () {
  echo "$1,$2" >> database
}
db_get () {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```
这个数据库的写性能很好，只需要追加到文件末尾。但是读性能非常不好，`db_get` 必须从头到尾扫描整个文件。

为了高效地查找数据库中特定键的值，需要新的数据结构：**索引**。背后的基本思想是：保存一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。针对不同的查询方式可以定义不同的路标。

索引是基于原始数据*派生*而来的额外数据。这里涉及到存储系统中重要的*权衡设计*：适当的索引可以加速读取查询，但是每个索引都会减慢写速度。通常，需要应用开发人员，基于对应用程序的典型查询模式的了解，手动选择索引。目的是加速查询的同时，不引入过多的写开销。

### kv 索引
首先我们以 kv 数据的索引开始。kv 类型并不是唯一可以索引的数据，但它随处可见，而且是其它更复杂索引的基础构建模块。

#### 内存中的 hash 索引
简单来说，kv 数据就是一个 `map`。既然已经有了内存数据结构的 hashmap，为什么不直接用它们索引磁盘上的数据呢？

索引策略：数据追加到磁盘文件里，内存中的 hashmap 记录 key 到 offset 的映射。读取时读取 offset 后去磁盘里取内容即可。

这确实是一个可行的做法。事实上，这就是 Bitcask (Riak 中的核心数据引擎) 的核心做法。Bitcask 可以提供高性能的读和写，只要所有的 key 可以放进内存。

适合场景：每个键的值频繁更新的场景。对于这种工作负载，有很多写操作，但是没有太多的 key。

如何回收已删除的内容所占用的磁盘空间？当文件达到一定大小后就切换到新的文件，然后在后台对已经冻结的文件做合并和压缩。压缩即是对于有覆盖的 key，只使用最新的值。压缩完成后，将读请求切换到合并后的文件上，并安全地删除旧的 segment。

每个 segment 现在都有自己的内存哈希表。为了找到键的值，需要先查询最新的表，找不到再检查第二新的表，以此类推。

还有一些实现上的细节问题：
* 删除一个键：追加一个墓碑
* 崩溃恢复：崩溃后，内存中的 hashmap 都丢失了，需要重建。原则上可以通过磁盘文件重建。实际上，可以把所有已冻结文件的 hashmap 持久化，这样可以更快地加载到内存中。只需要恢复最新的段文件。
* 部分写入：使用校验值，校验不通过则丢弃。
* 并发控制：只能有一个写线程，可以有多个读线程。

追加式设计比起原地更新文件的优点：
* 追加和分段合并都是顺序写，比随机写快得多。在 HDD 和 SDD 上的表现都更好。
* 段文件都是只追加或者不可变的，并发和崩溃恢复都要简单地多。
* 原地更新可能带来碎片化的问题。而追加与合并则没有碎片化的问题。

局限性：
* hashmap 必须全部放入内存。
* 区间查询效率不高。这是 hash 索引的必然。

为了克服这些限制，可以使用其它索引结构。

#### SSTable 和 LSM-Tree
在 kv 数据中，文件中 kv 对的顺序并不重要。所以可以在此基础上增加一个限制：要求 kv 对必须按 key 排序。即 hashmap 变为 `ordered_map`。这种格式称为 Sorted String Table，简称为 SSTable。SSTable 相比带哈希索引的日志段具有以下优点：
1. 合并段更加高效，即使文件大于可用内存。因为是有序的。
2. 不再需要在内存中保存所有的键的索引。只需要一个稀疏的索引，跳到最近的位置后，往前扫描即可。所以数据集可以远大于内存。
3. 区间查询效率很高。寻址到最早的位置后顺序读取即可。
4. 由于区间查询通常需要扫描读取范围内的多个记录，可以把这些记录放到一个块中并做压缩。既节省磁盘空间，也减少了 I/O 带宽占用。
##### 构建和维护
可以在内存中维护一棵平衡 BST，包括 key 和 value。当内存中的表大于某个阈值时，作为 SSTable 持久化到磁盘中。读取、合并和压缩都类似于之前的。

上述方案可以很好的工作。但是还存在一个问题：如果数据库崩溃，内存中尚未持久化的数据将会消失。解决方案：对每个写入，按写入顺序追加到磁盘中的日志。不需要按照 key 排序，因为其唯一作用是在崩溃后恢复内存表。当内存表持久化之后，该日志就会被丢弃。
##### 从 SSTable 到 LSM-Tree
SSTable 只是一种格式。这种索引的方式被称作 Log-Structured Merge-Tree。基于合并和压缩排序文件的存储引擎被叫做 LSM 存储引擎。
##### 性能优化
查找数据库中某个不存在的键时，LSM-Tree 算法可能很慢：需要访问所有段文件才能确认不存在某个键。优化：使用额外的 bloom-filter。如果某个键不存在，它可以很快告诉你结果。

SSTables 合并和压缩的具体顺序和时机可以有不同的策略。最常见的方式是*大小分级*和*分层压缩*。LevelDB 和 RocksDB 使用分层压缩，HBase 使用大小分级，Cassandra 则同时支持这两种方式。
* 大小分级：较新的和较小的文件被合并为更老的和更大的文件。
* 分层压缩：键范围被划分为较小的 SSTables，而较旧的数据被移动到单独的“级别”中，这使压缩可以进行更多的增量处理并使用更少的磁盘空间。

#### B-Tree
最广泛使用的索引结构是另一种不同的：B-tree。B 树是一种多叉搜索树，所有叶子节点的深度都是一样的。其设计理念是面向块或页的，传统上大小为 4 KB。这种设计更接近底层硬件。B 树的每一个节点存放在磁盘中的一页里。叶子页中包含每个内联键的值或者指向存放了值的页。

大多数数据库可以用 3-4 层的 B 树存下。分支因子为 500 的 4 KB 页的四级树可以存储高达 256 TB。
##### 使 B 树可靠
数据库可能在写某一页的中途崩溃，也可能在做需要修改多个页的操作的时候崩溃。从而导致索引结构被破坏。为了支持从崩溃中恢复，需要额外的数据结构：预写日志，即 WAL。每个修改先追加到 WAL，然后再修改树本身的页。当数据库从崩溃中恢复时，通过该日志将 B 树恢复到最近一致的状态。

另一个问题是要注意多个线程访问 B 树的并发控制，否则线程可能看到树处于不一致的状态。通常使用 latch 来保护树的数据结构。而 LSM-Tree 则没有这个问题，因为在后台执行合并，而且会原子地用新文件替换旧文件。
##### 优化 B 树
* 一些数据库不使用覆盖页和 WAL，而是使用写时复制。也即函数式的可持久化 B 树。这种方法对于并发控制也很有帮助。
* 保存键的缩略信息，而不是完整的键。因为在树的中间，只需要提供足够的信息来描述键的范围。这样可以使得分支因子更大，从而减少层数。
* 许多 B-tree 实现尝试对页布局，使得相邻叶子页可以按顺序保存在磁盘上。从而优化大段读取。

#### 对比 B-Tree 和 LSM-Tree
LSM-Tree 目前很有吸引力。根据经验，LSM-Tree 写入更快，B-Tree 读取更快。然而，最好测试特定的工作负载，这样方便更有效地比较。

##### 写吞吐量
B-Tree 必须至少写入两次：一次预写日志，一次写入树的页本身。由于反复压缩和 SSTable 的合并，日志结构也会重写数据多次。写放大越大，每秒可处理的写入就越少。

LSM-Tree 通常写入吞吐量更大，部分是因为具有较低的写放大（取决于配置），部分是因为它们以顺序紧凑的方式写入 SSTable，而不必重写磁盘的多个页。
##### 磁盘占用
LSM-Tree 更优。一方面它更好的支持压缩，另一方面它的碎片化程度更小，特别是在使用分层压缩时。
##### 读吞吐量和延迟
日志结构存储的缺点是压缩过程可能干扰正在进行的读写操作。这对吞吐量和平均响应时间的影响通常很小，但是对较高的百分位数有较大影响。而 B-Tree 的响应时间更具有确定性。
##### 写带宽
在写吞吐大时，磁盘写入带宽需要在初始写入和后台压缩之间共享。如果写入吞吐量很高，则压缩可能会跟不上，导致段文件不能及时合并，磁盘占用变大，读取速度也降低。通常需要额外的监控措施来发现这种情况。
##### 对事务的支持
B-Tree 的每个键都恰好唯一对应于树上的某个位置，而 LSM-Tree 的不同的段中可能具有相同键的多个副本。B-Tree 对事务支持更友好。键范围上的锁可以直接定义到树中。

### 其它索引结构
到目前为止，只讨论了 key-value 索引，它们像是关系模型中的主键索引。

二级索引也很常见。二级索引可以很容易地基于 key-value 索引来构建。主要区别在于可能有许多行具有相同的键。可以通过两种方式解决：value 扩展为一个包含所有匹配行的列表，或者对键追加行标识符来使每个键唯一。无论哪种方式，B-tree 和 LSM-Tree 都可以用作二级索引。
#### 在索引中存储值
索引中的值可以是以下两种：可能是实际的行，也可以指向实际存储行的其它地方。在后一种情况下，存储行的地方被称为堆文件。堆文件方法，在有多个二级索引时，可以避免复制数据。

在某些情况下，从索引到堆文件的跳转对于读取来说太浪费。因此希望把行直接存储在索引中。被称为**聚簇索引**。

聚簇索引（在索引中直接保存行）和非聚簇索引（索引中仅存储行的引用）之间有一种折中设计，称为覆盖索引。只有一部分行直接保存在索引里，从而加速某些简单查询。
#### 多列索引
需要同时查询多个列时，上面那些索引结构是不够的。
##### 级联索引
最常见的多列索引类型称为级联索引。即将多列的字段连接在一起组成一个键。例如电话本提供姓名到电话号码的索引。由于先按照姓排序，索引可以用于查询所有具有特定姓的人，也可以查询特定姓名的人。但不可以查询所有特定名字的人。
##### 多维索引
多维索引是更普遍的一次查询多个列的方法。这对地理空间数据尤其重要。例如，给定经度范围和维度范围，查询区域内所有的饭店。常见的解决方法是使用专门的空间索引，如 R 树。

一个有趣的想法是，多维索引不仅适用于地理位置。例如，查询颜色范围可以使用颜色维度上的三维索引（红，绿，蓝）。
#### 全文搜索和模糊索引
到目前为止的所有索引都是确定性的索引。它们不支持搜索类似的键，如拼写错误的单词。这种模糊查询需要不同的技术。

在 Luence 中，内存中的索引是键的字符串的有限状态自动机，类似 Trie。这个自动机可以转换成 Levenshtein 自动机，它支持在给定编辑距离内高效地搜索单词。

其它模糊搜索技术则沿着文档分类和机器学习的方向发展。
#### 在内存中保存所有数据
本章迄今为止讨论的数据结构都是为了适应磁盘限制。为了在磁盘上获得良好的读写性能，需要精心安排磁盘上的数据布局。然而这些都是值得的，因为磁盘有两个显著的优点：持久性，成本比内存低很多。随着内存变得便宜，内存数据库也成为可能。

旨在实现持久性的内存数据库也需要把数据写入磁盘。尽管如此，磁盘仅仅用作为了持久性目的的追加日志，读取完全靠内存服务。

与直觉相反的是，内存数据库的**性能优势**并不是因为它们不需要从磁盘读取。而是因为它们避免了对内存数据使用易于写入磁盘的格式的开销。

除了性能外，一个有意思的地方是：它提供了基于磁盘索引难以实现的数据模型。例如 Redis 为优先级队列和集合都提供了类似数据库的访问接口。

最近的研究表明，内存数据库架构可以扩展到支持远大于可用内存的数据集，而不会导致以磁盘为中心架构的开销。通过把最近最少使用的数据从内存换出到磁盘，数据库可以更有效地利用有限的内存。数据库可以在记录的级别而非页级别管理内存，所以比操作系统更有效。不过这种方法仍然需要索引完全放入内存。

## 两种工作负载：事务处理和分析处理
事务处理：只是意味着允许客户端进行低延迟读取和写入。不一定具有 ACID 属性。
分析处理：用于数据分析。通常，分析查询需要扫描大量记录，每个记录只读取少数几列，并汇总结果。
| 属性 | OLTP | OLAP |
| - | - | - |
| 主要读特征 | 基于键，每次查询返回少量记录 | 扫描大量记录 |
| 主要写特征 | 随机访问，低延迟写入 | 批量导入 (ETL) 或事件流 |
| 典型使用场景 | 终端用户，通过网络应用程序 | 内部分析师，为决策提供支持 |
| 数据表征 | 最新的数据状态 | 随着时间而变化的数据的所有历史 |
| 数据规模 | GB 到 TB | TB 到 PB |

最初，相同数据库可以同时用于事务处理和分析查询。SQL 可以同时胜任。后来，公司放弃使用 OLTP 系统分析，而是在单独的数据库上进行分析。这个单独的数据库称之为数据仓库。
### 数据仓库
一个企业可能有很多个独立运行的 OLTP 系统。这些系统对于业务的运行非常重要，往往需要它们高度可用。管理员通常不愿意让业务分析人员在 OLTP 数据库上直接运行临时分析查询，因为这样可能会损害并发执行事务的性能，从而影响线上业务。

相比之下，在一个单独的数据库上运行分析查询则安全许多。数据仓库包含公司所有 OLTP 系统的只读副本。将数据从 OLTP 系统导入数据仓库的过程称为**提取-转换-加载** (ETL)。

使用单独的数据仓库进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化。本章前面介绍的索引算法只适用于事务处理，但不擅长应对分析查询。
#### OLTP 数据库和数据仓库的对比
数据仓库最常见的数据模型是关系型，原因是 SQL 适合用来做分析查询。

表面上看，数据仓库和关系型 OLTP 数据库看起来很相似，它们都具有 SQL 查询接口。然而，系统内部的差异很大，因为它们针对迥然不同的查询模式进行了各自的优化。虽然接口一样，事务处理和分析处理通常是两个独立的存储和查询引擎。
### 分析型业务的 schema：星形与雪花形
根据不同的应用需求，事务处理领域使用了多种不同的数据模型。而分析型业务的数据模型则要少得多。许多数据仓库都相当公式化地使用了**星形模式**，也称维度建模。

模式的中心是一个**事实表** (fact)。事实表的每一行表示在特定时间发生的事件。事实表可能会变得非常庞大，有可能大部分内容都保存在事实表中。

事实表中的一些列是属性，其它列可能会引用其它表的外键。其它表称为**维度表**，代表事实的一维。日期和时间通常使用维度表来表示，这样可以对日期的相关信息进行编码，从而查询可以对比假期和非假期之间的销售情况。

星形模式指事实表位于中心，被维度表包围。这些表的连接就像星星的光芒。变体是**雪花模式**，其中维度表进一步细分为其它维度。雪花模式更规范化，但是星形模式通常是首选，因为分析人员使用起来更简单。

在典型的数据仓库中，事实表通常非常宽，可能有几百列。维度表也可能非常宽。

## 为分析型优化：面向列的存储
如果事实表中有数以万亿行，则高效地存储和查询这些数据将成为一个挑战。维度表通常小得多，因此本节只关心事实表。

虽然事实表通常超过 100 列，但典型的分析查询往往一次只访问其中的 4 或 5 列。而不管是关系型还是文档型数据库，一行或者一个文档都是以连续的字节存储。读取和解析一整行非常浪费。

面向列的存储的想法很简单：不要将一行中的所有值存储在一起，而是将每列中的所有值存储在一起。查询只需要读取和解析需要的那些列，节省了大量工作。
### 列压缩
除了仅从磁盘中加载需要的列以外，还可以通过压缩数据来进一步降低对磁盘吞吐量的要求。而面向列的存储恰好非常适合压缩。

在数据仓库中特别有效的一种技术是位图 (bitmap) 编码。如果一列有 n 个可能的值，则编码为 n 个单独的位图：一个位图对应一个值，如果某一行取该值，就在该位图对应的位上取 1，否则为 0。

位图中只有如果 n 很大，那么位图中大部分都是 0。此时，可以对位图进行**游程编码**（例如，4 个 0，3 个 1）。这样列的编码非常紧凑。

这些位图索引非常适合在数据仓库中常见的查询。查询中的 and 和 or 可以直接转换为位图的按位与和按位或。
#### 内存带宽和向量化处理
将数据从磁盘加载到内存不是唯一的瓶颈。还需要关心如何高效地从内存加载到 CPU 缓存，避免分支错误预测和气泡， 并利用 CPU 的 SIMD 指令。

除了减少需要从磁盘加载的数据量之外，面向列的存储布局也有利于高效利用 CPU 周期。列压缩使得列中的更多行可以加载到 CPU 缓存，而之前的按位与和按位或可以高效利用 SIMD 指令。这被称为**向量化处理**。

### 列存储中的顺序
列存储中，行的顺序不太重要。数据库可以自己规定排序规则。可以基于常见查询的知识来选择以哪些列为 key 进行排序。例如，如果经常按日期查询，则可以选择日期为第一个键。

排序的另一个优点是它可以帮助进一步压缩列。主排序列上，相同的值都被聚集到了一起。如果不同的值的数量比较少，一个简单的游程编码就可以压缩很多。
#### 使用多种排序
考虑到不同的查询会从不同的排序中受益，那么为什么不以多种不同的方式存储相同的数据呢？

无论如何，数据要被复制到多台机器。不妨在不同机器上使用不同的方式排序冗余数据，以便在处理查询时选择最适合的副本进行查询。

这有些类似有多个二级索引。区别是二级索引指向保存数据的位置，而列存储中是直接保存了副本。
### 写操作
上面这些操作对读取很有帮助，但是让写入更加困难。

幸运的是我们可以使用类似 LSM—Tree 的方式。所有写入首先进入内存存储区，将其加入已排序的结构中并且准备写入磁盘。内存中的存储是面向行还是面向列无关紧要。当积累了足够多写入时，它们将与磁盘中的列文件合并并批量写入新文件。查询时同样需要同时查询内存和磁盘并合并结果。

### 加速聚合：物化视图和数据立方体
数据仓库另一个值得一提的是物化聚合。目的是优化常见查询。思想是如果许多不同查询使用相同的聚合，为什么不缓存这些查询的结果呢？

物化视图是查询结果的实际副本，并被写入磁盘。而关系数据模型中的虚拟视图知识用于编写查询的快捷方式，可以认为只是对查询结果命名。

当底层数据变化时，物化视图也需要随之更新。数据库可以自动执行，但这种更新方式会影响数据写入性能，这就是为什么在 OLTP 数据库中不经常使用物化视图的原因。

#### 数据立方体
物化视图的常见的一种特殊情况是数据立方体。数据立方体中缓存的是形如 `SELECT COUNT(*) FROM ... GROUP BY date, product` 的查询结果。`GROUP BY` 后面有 n 列，则形成了一个 n 维的立方体。可以沿着某一维进一步聚合，以减少维度。

数据立方体的优点是某些查询非常快，主要是因为它们已被预先计算出来。缺点则是，缺乏像查询原始数据那样的灵活性。因此，数据仓库还是需要保留尽可能多的原始数据，仅使用数据立方体加速特定查询。

## 小结
概括来讲，存储引擎按用途分为两大类：事务处理 (OLTP) 和分析处理 (OLAP)。

在 OLTP 方面，有两个主要流派的存储引擎：日志结构流 (LSM-Tree) 和原地更新流 (B-Tree)。

此外，介绍了一些更复杂的索引结构，和为全内存优化的数据库。

在 OLAP 方面，其工作负载与 OLTP 非常不同：当查询需要在大量行中顺序扫描时，索引的重要性显著降低。相反，最重要的是如何紧凑地编码数据。列存储帮助了实现这一目标。