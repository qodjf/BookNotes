# 数据编码与演化

应用程序不可避免地需要随着时间而变化。大多数情况下，更改应用程序功能时，也需要更改其存储的数据：可能需要增加字段，或者改变已有的字段。

当数据格式或者 schema 改变时，代码也需要相应的更改。然而这并非易事：
* 对于服务端应用，可能需要执行滚动升级。
* 对于客户端应用，不能期望用户很快执行升级。

这意味着新旧版本的代码，以及新旧数据格式，可能会在系统内共存。为了使系统顺利运行，需要保持双向的兼容性：
* 向后兼容：新代码可以读取旧数据
* 向前兼容：旧代码可以读取新数据

向后兼容通常不难实现，实在不行只需保留旧的代码处理旧数据。向前兼容比较棘手，它需要旧代码忽略新版本的代码所做的添加。

本章将介绍多种编码格式，这里需要关注的问题是它们如何处理模式变化，以及如何支持新旧数据和新旧代码共存的系统。之后，还将讨论这些格式如何用于数据存储和通信场景。

## 数据编码格式
程序使用两种不同的数据表示形式：内存中的数据结构和通过网络发送的字节序列。两种格式的转化分别称为编码和解码。
### 语言特定的格式
编程语言内置的格式虽然使用起来方便，但是有如下缺点：
* 通常与特定编程语言绑定，用其它语言访问时非常困难。
* 安全问题。为了恢复任意类的数据，解码过程需要能够实例化任意的类。可能被用来执行任意代码。
* 在这些库中，多版本兼容性问题通常不被考虑。
* 效率低，包括编码解码时间和编码结构的大小。

由于以上原因，使用语言内置的编码不是个好主意，除非只是为了临时尝试。
### JSON，XML 和二进制变种
目标转向可由不同编程语言使用的标准化编码。显然 JSON 和 XML 是其中的佼佼者。

JSON、XML 和 CSV 都是文本格式，因此具有不错的可读性。但是它们也有一些微妙的问题：
* 数字编码模糊
* 不支持二进制字节序列
* JSON 和 XML 虽然支持 schema，但是难以学习和使用。CSV 没有任何 schema 支持。

尽管它们有着各种各样的问题，但总体来说很受欢迎。因为它们使得不同组织就格式达成一致。

在 JSON 和 XML 之上有一些二进制编码上的改进，使得格式更加紧凑。然而，由于它们没有规定模式，所以需要在编码数据时包含所有的对象字段名称。所以它们的紧凑性十分有限。
### Thrift 和 Protocol Buffer
Thrift 和 protobuf 是基于相同原理的两种二进制编码库。它们都需要 schema 来编码任意的数据。

protobuf 的示例如下：
``` protobuf
message Person {
  required string user_name = 1;
  optional int64 favorite_number = 2;
  repeated string interests = 3;
}
```
它们各有各自的代码生成工具，可以根据模式定义生成多种编程语言的类。由于是代码生成而不是反射，所以避免了前面所说的实例化任意类的安全问题。

Thrift 有两种不同的二进制编码格式，分别是 BinaryProtocol 和 CompactProtocol。

在 BinaryProtocol 中，每一个字段的编码有几个部分：类型、tag、长度（可选）、实际内容。与 JSON 等格式的最大区别是，编码后的数据中没有字段名。而是使用数字 tag，这些数字是模式定义中出现的数字。从而格式更加紧凑。

在 CompactProtocol 中，空间被进一步压缩。字段类型和字段标签被打包到一个字节中。整数使用可边长度整数实现：每字节的最高位用来指示是否还有更多的字节，越大的数字所需要的字节数越多。

protobuf 与 CompactProtocol 的格式非常相似。需要注意的一个细节是，`optional` 和 `required` 对字段如何编码没有任何影响。影响是在解码时，如果标记为 `required` 的字段没有值，则运行时检查会出现失败。

Thrift 和 protobuf 如何应对模式演化呢？
#### 字段名称和字段标签演化
字段名称可以随意更改，因为它们不会出现在编码结果中。而字段标签不可以随便更改，它会导致之前编码的数据无效。
#### 增加字段或删除字段
可以增加新的字段，只需要使用不同的 tag。
* 向前兼容：旧代码读取新数据时，会忽略新的字段。
* 向后兼容：新的代码总是可以读取旧的数据。唯一的细节是，不能添加 `required` 字段，因为旧数据里没有对应的值。因此，只能添加可选的或者具有默认值的字段。

删除字段类似添加字段，不过向前和向后兼容性问题相反。
* 向前兼容：只能删除可选的字段
* 向后兼容：需要使用不同的 tag
#### 数据类型演化
可以改变字段的类型吗？这是有可能的，但是有丢失精度或者阶段的风险。例如在不同长度的整数之间转换。

protobuf 中的一个奇怪的细节是，它没有列表或数组类型，而是有字段的重复标记 (`repeated`)。可以将可选单值字段更改为重复字段。读取旧数据的新代码会看到包含零个或者一个元素的列表，读取新数据的旧代码则只能看到列表的最后一个元素。

Thrift 有单独的列表类型，不支持从单值到多值的改变。但是它具有支持嵌套列表的优点。
### Avro
Apache Avro 是另一种二进制编码模式，与 Protobuf 和 Thrift 有一些有趣的差异。Thrift 不适合 Hadoop 的用例。

Avro 也使用模式来指定编码的数据的结构。它有两种模式语言，有易于人工编辑的 IDL，也有易于机器读取的 JSON 表示。
```Avro
record Person {
  string               userName;
  union { null, long } favoriteNumber = null;
  array<string>        interests;
}
```
首先，注意到模式中没有标签编号。所以这种编码方式最紧凑。其次，在编码后的序列中，也没有什么标识字段或数据类型的字节。

为了解析二进制数据，按照它们出现在模式中的顺序遍历这些字段读取其值，直接采用模式语言中每个字段的数据类型。这意味着，只有当读模式和写模式完全相同时，才能正确解码二进制数据。

实际上并非如此。Avro 还支持模式演化。

#### 写模式与读模式
Avro 的关键思想是，写模式和读模式不必完全一样，而只需要保持兼容。解码时，Avro 库按写模式读取，并将写模式转换成读模式的数据结构。

例如，字段顺序不同时，模式解析可以通过字段名来匹配字段来把写模式转换成读模式。读取到不需要的字段时，忽略它。读取不存在的字段时，使用默认值。

#### 模式演化规则
字段添加或删除：同 Protobuf 一样，为了保持兼容性，Avro 只能添加或删除具有默认值的字段。

此外，如果允许字段为 `null`，则必须使得 `null` 为联合类型的第一个类型。因此，Avro 不具有可选和必需的标签。

字段类型：只要 Avro 可以转换类型，就可以改变字段的类型。

字段名称：更改名称也可以，就是比较棘手。因为 Avro 靠名称而非标签匹配数据。reader 的模式里可以包含数据名称的别名，这意味着向后兼容，但是不向前兼容。因为旧代码无法读取按新的模式写入的数据。同样的，向联合中添加分支也是向后兼容但不向前兼容。

#### 写模式在哪
首先读模式就是此时代码里使用的模式。而编码后的数据的写模式是什么，则取决于 Avro 的上下文。例如：
* 有很多记录的大文件。只需要把模式放在文件的最开头。
* 具有单独写入记录的数据库。最简单的解决方案是在每个编码记录上包含一个版本号，并在数据库中保存一个模式版本列表。
* 通过网络连接发送记录。两个进程可以在建立连接时协商模式版本，然后在连接的生命周期内使用该模式。

在任何情况下，提供一个记录模式版本信息的数据库都非常有用。它可以充当一个模式演化的文档，可以用来检查模式的兼容性情况。

#### 动态生成的模式
与 Protobuf 和 Thrift 相比，Avro 的一个优点是不包含标签号。这有什么好处？

关键之处在于，Avro 对动态生成的模式更友好。例如，根据关系数据库中的表的模式，自动生成 Avro 的模式。模式变化时，也可以很方便地重新生成，而无需考虑标签号冲突的可能。

这种动态生成的模式，根本不是 Thrift 或 Protobuf 的设计目标，而是 Avro 的设计目标。

### 模式 (schema) 的优点
* 比 JSON 等二进制编码更加紧凑。因为编码后的数据中不包含字段名称。
* 模式是一种有价值的文档形式。因为模式直接在代码中，所以总是和代码保持一致。
* 维护模式版本信息的数据库有助于检查兼容性。
* 对于静态类型编程语言的用户来说，从模式生成代码的能力是有用的，提供了编译时的数据类型检查。

总之，通过模式演化，提供了与无模式或读时模式的 JSON 数据库同样的灵活性，同时还提供了有关数据和工具方面更好的保障。
## 数据流动的模式 (mode)
前面我们提到，兼容性是执行编码的一个进程和执行解码的另一个进程之间的关系。

这是一个相当抽象的想法。具体来说，数据可以通过多种方式从一个进程流向另一个进程。
* 通过数据库
* 通过服务调用
* 通过异步消息传递

### 基于数据库的数据流动
基于数据库的数据流，既需要向后兼容也需要向前兼容。

然而，还有一个额外的障碍。旧版本代码，读取了新版本的数据，修改后再写回时，很可能会丢弃它不认识的字段。理想的行为是保持不认识的字段不变。解决这个问题并不困难，重要的是要有这方面的意识。

#### 不同版本的数据共存
应用程序可以很快替换，数据库里的数据却可能保存很久。数据比代码更长久。模式演化支持整个数据库看起来是采用单个模式编码，即使底层存储包含各个模式所编码的记录。

归档时，一般会使用最新的模式统一编码。这也是使用分析友好的列存储的好机会。

### 基于服务的数据流动
服务器公开的 API 叫做服务。将大型应用程序按照功能分解为较小的服务，这种构建方式称为面向服务的体系结构 (SOA)。

面向服务/微服务体系结构的一个关键设计目标是，通过使服务可独立部署和演化，让应用程序更易于更改和维护。因此，服务器和客户端使用的数据编码必须在不同版本的服务 API 之间兼容。

#### 网络服务
使用 HTTP 作为底层通讯协议的服务，被称为 *Web 服务*。

有两种流行的 Web 服务方法：REST 和 SOAP。它们在设计理念上几乎截然不同。REST 不是一种协议，而是一个基于 HTTP 原则的设计理念。相比之下，SOAP 是一种基于 XML 的协议。虽然它最常用于 HTTP，但其目的是独立于 HTTP，并避免使用大多数 HTTP 功能。

SOAP 并不是 SOA 的必要条件，它们只是恰好名字前缀相同。SOAP 是一种特定技术，SOA 是构建系统的一种一般方法。

RESTful 由于其简单性更受欢迎。

#### 远程过程调用
除了 Web 服务以外，还有一种广泛使用的思想被用来通过网络发出 API 请求，叫做远程过程调用。
##### RPC 的问题
RPC 模型试图使向远程网络服务发出请求看起来与在同一进程中调用函数相同（这种抽象称为位置透明）。虽然看起来很方便，但这种方法*在根本上是有缺陷的*。网络请求和本地调用非常不同：
* 本地函数是可预测的，成功与失败仅取决于控制的参数。网络请求是不可预测的，容易受到网络环境和远端机器的影响。
* 网络调用没有返回时，无法判断是否调用已经在远端执行。
* 重试可能导致请求执行多次。

这些因素意味着，尝试使远程服务看起来像本地调用一样毫无意义，因为它们是根本上不同的事情。REST 的部分吸引力在于，它并不试图隐藏它是网络协议的事实。

##### RPC 的发展方向
新一代的 RPC 框架更加明确了远程请求与本地调用不同的事实。例如，用 Future 来封装可能失败的异步操作。其中一些框架还提供了服务发现。

使用二进制编码的 RPC 协议比 JSON 性能更好。而 RESTful 可读性更好，且工具生态系统更加庞大，因此易于实验和调试。因此，公共 API 通常使用 REST。而同一组织内部则可以使用 RPC 框架。

#### 编码演化
与基于数据库的数据流相比，此处可以做一个简化的假设：首先所有的服务端应用程序先更新，其次是所有客户端。因此，只需要在请求上具有向后兼容性（新的服务端需要读取旧的客户端发的请求），而在响应上具有向前兼容性（旧的客户端需要读取新的服务端的响应）。

RPC 的兼容性取决于它所使用的具体编码技术，包括 Thrift、gRPC、JSON 等。

RPC 方案用于跨组织边界的通信时，兼容性更加难以保持。因为无法强制其客户端升级，所以需要长期保持兼容性，可能是无限期的。如果不得不做一些破坏兼容性的修改，则服务提供者往往会同时维护多个版本的服务 API。API 版本管理目前没有统一的方案。

### 基于消息传递的数据流动
基于网络的数据流动是完全同步的，基于数据库的数据流动是完全异步的。在它们之间，还有异步消息传递系统。它和 RPC 的相似之处在于低延迟。它与数据库的相似之处在于通过消息代理暂存消息。

与直接 RPC 相比，使用消息代理有以下几个*优点*：
* 如果接收方过载，消息代理可以充当缓冲，从而提高可靠性，避免消息丢失
* 可以自动将消息重新发送到崩溃的进程，避免消息丢失
* 在逻辑上将发送方与接收方分离

这种通信模式是异步的：发送者不会等待消息被传递，而只是发送然后忘记它。

#### 消息代理
典型如 Kafka。生产者发布消息到某个主题，消息代理确保消息被传递给主题的一个或多个订阅者。在同一主题上可以有多个生产者和消费者。

#### 分布式 Actor 框架
Actor 模型是用于单个进程中并发的编程模型。Actor 之间不共享状态，而是通过消息来与其它 Actor 通信。在分布式 Actor 框架中，无论发送方和接收方在同一个节点上还是在不同节点上，都使用相同的消息传递机制。如果位于不同的节点上，则消息被编码为字节序列通过网络发送。

相比 RPC，位置透明性在 Actor 模型中*更有效*，因为 Actor 模型已经假定消息可能会丢失，即使在单个进程中也是如此。因此，本地和远程通信之间根本上的不匹配的概率更小。

分布式 Actor 框架实质上是将消息代理和 Actor 编程模型集成到单个框架中。但是，滚动升级时仍需要担心向前和向后兼容性问题。

## 小结
本章研究了多种数据编码方式及其兼容性情况，其如何支持模式演化。

还讨论了数据流的几种模型，说明了数据编码在不同场景下非常重要：包括数据库，服务，异步消息传递。

最后，得出了这样的结论：只要稍加小心，向前/向后兼容性和滚动升级是**完全可以实现的**。