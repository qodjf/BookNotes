# 分区
上一章讨论了复制技术，即在不同节点上保存相同数据的多个副本。然而，如果数据的总大小超过单个节点所能承载的上限，只使用复制技术是不够的。因此，我们需要把数据拆分成分区，再分配给多个节点处理。

分区通常是这样的：每一条数据只属于一个分区。实际上，每个分区可以被视为一个完整的小型数据库，虽然数据库可能存在一些跨分区的操作。

**目的**：可扩展性。数据量增多时，只需要加更多的节点。负载自然地分布到各个节点上。

## 分区和复制
分区通常与复制结合使用，即每个分区在多个节点都有副本。一个节点上可能存储了多个分区。这样既得到了可扩展性，也提高了容错性。

## KV 数据的分区
分区的**主要目标**是将数据和查询负载均匀分布在所有节点上。如果可以做到，则可以线性水平扩展，这是最理想最优的情况。

而如果分区不均匀（称之为倾斜），就可能出现“一核有难，9 核围观”的现象，无法发挥出所有节点的全部性能。

避免热点最简单的办法是将记录随机分配给所有节点。这种方法确实很均匀，然而缺点是读取特定 key 时，无法知道它在哪个节点上，所以不得不并行查询所有节点。因此，一定要有一个规则去决定 key 属于哪个分区，然后去查询对应的节点。

### 根据 key 的范围分区
#### 实现
一种分区方式是把 key 的范围切分为一个个更小的区间，每个分区对应一个区间。根据 key 可以知道它属于哪个分区，如果还知道分区属于哪个节点，就可以把请求发送到对应节点上。

区间的切分不一定要均匀，这是因为数据本身可能就不均匀。例如，以 A 开头的单词很多，以 Z 开头的单词却只有几页。为了更均匀地分布数据，分区边界需要适配数据本身的分布特征。

分区边界可以由管理员手动指定，也可以由数据库自动选择。采用这种分区策略的系统包括 Bigtable，其开源实现 HBase，RethinkDB 和 2.4 版本之前的 MongoDB。

#### 优点：支持区间查询
如果每个分区内按照 key 排序保存（例如 LSM-Tree），则这种分区方式可以轻松支持区间查询。原因很简单，按区间的顺序把所有区间合到一起，则得到了按顺序排列的所有数据。可以认为 key 是一个多列索引，例如如果 key 是年月日，则我们可以按年的区间查询，也可以按年月的区间查询。

#### 缺点：可能导致热点
然而，其缺点是某些访问模式会导致热点。例如，如果 key 是时间戳，则分区对应一个时间范围，例如每天一个分区。则每天的写入操作都只对应一个分区，而其它分区则处于空闲状态。

为了解决上述问题，需要使用时间戳以外的其它内容作为关键字的第一项，后面再接上时间戳。

### 根据 key 的 hash 分区
### 负载倾斜和热点问题

## 二级索引的分区
### partitioning by document
### partitioning by term

## 分区再平衡
### 再平衡的策略
#### 为什么不用 mod
#### 固定数量的分区
#### 动态调整分区
#### 分区数与节点数成正比

### 运维：自动与手动再平衡

## 请求路由